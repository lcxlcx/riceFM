# riceFM Overview
riceFM draws inspiration from the core design principles of language models, treating single-cell transcriptomic profiles as "sentences" in natural language and gene expression values as the "words" that compose these sentences. By leveraging a self-supervised generative pre-training strategy, riceFM successfully constructs a foundational model for rice single-cell analysis. To ensure strong generalization capabilities and high biological representation fidelity, riceFM is pre-trained on a large-scale, multi-dimensional dataset—comprising approximately 700,000 rice single-cell transcriptomes and integrated with 300,000 rice spatial transcriptomic profiles. This constitutes the largest and most comprehensive training dataset currently available in the rice research field. The data originate from key rice tissues and organs—including roots, stems, leaves, flowers, and seeds—and span multiple developmental stages and environmental stress conditions, ensuring both data diversity and a solid foundation for the model to capture both universal and cell-type-specific features of rice cells.

In terms of core performance, riceFM demonstrates remarkable technical advantages. In cell clustering tasks, the cell embeddings generated by riceFM accurately distinguish between different tissue types, cellular subpopulations, and functional states. The clustering results achieve an AvgBIO score as high as 0.74—significantly outperforming conventional methods—with well-defined cluster boundaries and high intra-cluster compactness, effectively avoiding issues such as dispersion of similar cells or mixing of dissimilar ones. In cell type annotation tasks, after fine-tuning with only a small amount of manually labeled data, riceFM achieves an average annotation accuracy of 0.89 across 8 major rice tissues and 56 distinct cell types. Notably, its accuracy exceeds 0.92 for highly specialized cell types such as root hair cells and guard cells, substantially reducing both the manual effort and subjective errors associated with traditional annotation approaches.

# Requirements

```txt
npu-driver==23.0.rc2.2
CANN==7.0.1
python==3.10.18
torch==2.1.0
torch-npu==2.1.0
scanpy==1.10.4
scib==1.1.7
scikit-learn==1.6.1
scikit-misc==0.5.1
scipy==1.14.1
scvi-tools==0.20.3
transformers==4.46.3
datasets==2.21.0
```


# Pretraining Pipeline:

1. First, convert h5ad data into the input format required for riceFM pretraining.
  
   Conversion script:  [build_data.py](/run/build_data.py)

   Parameter descriptions:  
   - `--input-dir`: Directory storing all h5ad files  
   - `--output-dir`: Output directory  
   - `--vocab-file`: Gene vocabulary, a JSON file in the format `{"gene1": 0, "gene2": 1}`  

2. Execute the pretraining script  
   - [pretrain.py](/run/pretrain.py): Code for the model pretraining process  
   - [run_pretrain_single_npu.sh](/run/run_pretrain_single_npu.sh): Single-NPU training script; users can modify or add model-related configurations as needed  
   - [run_pretrain_multi_npu.sh](/run/run_pretrain_multi_npu.sh): Multi-NPU training script; for other clusters, refer to the [pretrain.sh](/run/pretrain.sh) script (using `torchrun`)




# Tutorial
Please refer to the usage tutorials for applying pre-trained riceFM models to various downstream tasks. 

Tutorials can be found here:[Tutorials](/tutorials)




# Download the pre-trained riceFM model 

Here is the pretrained models. Please find the links for downloading the checkpoint folders. 

|Model name|Description|Download|
|:-|:-|:-|
|riceFM|riceFM was pretrained using multi-omics data, <br> with a pretraining dataset comprising more than 700,000 <br> rice single-cell transcriptomes and integrating over <br> 300,000 rice spatial transcriptomic profiles.|[link](https://drive.google.com/drive/folders/1kDpOd5D6KaMak1mHgY3Dcb_OZF2NrxGq?usp=drive_link)|
